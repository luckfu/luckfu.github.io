+++
author = "luckfu"
title = "书生·浦语大模型实战 笔记--1"
date = "2024-01-03"
description = "书生·浦语大模型实战 笔记--1"
tags = [
    "internLM","LLMs","python"
]
toc = true
categories = [
    "LLM","internLM"
    "python","LangChain"
]
series = ["LLMs","python","Finetuning"]
aliases = ["migrate-from-jekyl"]
+++

# 书生·浦语大模型系列的特点

- 轻量级：InternLM-7B
70亿模型参数
1000亿训练token数据
长语境能力，支持8K语境窗口长度
通用工具调用能力，多种工具调用模板
- 中量级：InternLM-20B
200亿模型参数，在模型能力与推理代价间取得平衡
采用深而窄的结果，降低推理计算量但提高推理能力
4K训练语境长度，推理时可外推至16K
- 重量级：1230亿模型参数，强大的性能
极强推理能力、全面的知识覆盖面、超级理解能力与对话能力
准确的API调用能力，可实现各类Agent


# 浦语大模型全链路开源体系生态

![](/post/images/2024-01-03/internLM.png)

从模型到应用流程
![](/post/images/2024-01-03/model2app.png)

> 书生·浦语大模型的全链路开源体系覆盖了大模型应用的方方面面，因为工作关系，我个人比较关注的是增量预训练和有监督微调，评测、和应用部署部分来实现垂直领域应用
<!--more-->
- 微调：XTuner
支持全参数微调
支持LoRA等低成本微调

- 评测：OpenCompass
全方位评测，性能可复现80套评测集，40万道题目

- 应用：
Legent（轻量级智能体框架）：搭建简单的智能体
AgentLego：支持多种智能体，支持代码解释器等多种工具

